{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction and EDA\n",
    "\n",
    "This notebook extracts the data and performs analysis to test for feature availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Filepaths: ['../data/data/a__geo.csv', '../data/data/a__company.csv']\n",
      "INFO:root:Reading ../data/data/a__geo.csv into key a__geo\n",
      "INFO:root:Reading ../data/data/a__company.csv into key a__company\n",
      "INFO:root:Filepaths: ['../data/data/b__company.csv', '../data/data/b__hierarchy.csv', '../data/data/b__address.csv']\n",
      "INFO:root:Reading ../data/data/b__company.csv into key b__company\n",
      "INFO:root:Reading ../data/data/b__hierarchy.csv into key b__hierarchy\n",
      "INFO:root:Reading ../data/data/b__address.csv into key b__address\n",
      "/Users/cullenpaulisick/opt/anaconda3/envs/webscraping/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (11,15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "INFO:root:Merging values of dict_keys(['a__geo', 'a__company'])\n",
      "INFO:root:Merged frames into one with columns Index(['geo_id', 'zipcode_a__geo', 'is_primary_a__geo', 'latitude_a__geo',\n",
      "       'longitude_a__geo', 'elevation_a__geo', 'state_a__geo',\n",
      "       'state_full_name_a__geo', 'area_code_a__geo', 'city_a__geo',\n",
      "       'city_display_a__geo', 'county_a__geo', 'county_fips_a__geo',\n",
      "       'state_fips_a__geo', 'timezone_a__geo', 'daylight_saving_a__geo',\n",
      "       'region_a__geo', 'division_a__geo', 'congress_district_a__geo',\n",
      "       'congress_land_area_a__geo', 'country_a__geo', 'continent_a__geo',\n",
      "       'country_iso2_a__geo', 'vendor_id', 'parent_vendor_id_a__company',\n",
      "       'top_vendor_id_a__company', 'cnt_children_a__company',\n",
      "       'orgtype_id_a__company', 'name_a__company', 'email_a__company',\n",
      "       'phone_a__company', 'fax_a__company', 'dunsnumber_a__company',\n",
      "       'websiteurl_a__company', 'address_a__company', 'address1_a__company',\n",
      "       'address2_a__company', 'country_a__company', 'zipcode_a__company',\n",
      "       'parentdunsnumber_a__company', 'score_a__company', 'cnt_opp_a__company',\n",
      "       'bucket_id_a__company', 'load_date_a__company', 'lvl_a__company'],\n",
      "      dtype='object')\n",
      "INFO:root:Merging values of dict_keys(['b__company', 'b__hierarchy', 'b__address'])\n",
      "INFO:root:Merged frames into one with columns Index(['b_entity_id', 'entity_name_b__company',\n",
      "       'entity_proper_name_b__company', 'primary_sic_code_b__company',\n",
      "       'industry_code_b__company', 'sector_code_b__company',\n",
      "       'iso_country_b__company', 'metro_area_b__company',\n",
      "       'state_province_b__company', 'zip_postal_code_b__company',\n",
      "       'web_site_b__company', 'entity_type_b__company',\n",
      "       'entity_sub_type_b__company', 'year_founded_b__company',\n",
      "       'iso_country_incorp_b__company', 'iso_country_cor_b__company',\n",
      "       'nace_code_b__company', 'b_parent_entity_id_b__hierarchy',\n",
      "       'b_ultimate_parent_entity_id_b__hierarchy', 'address_id_b__address',\n",
      "       'location_city_b__address', 'state_province_b__address',\n",
      "       'location_postal_code_b__address', 'city_state_zip_b__address',\n",
      "       'location_street1_b__address', 'location_street2_b__address',\n",
      "       'location_street3_b__address', 'iso_country_b__address',\n",
      "       'tele_country_b__address', 'tele_area_b__address', 'tele_b__address',\n",
      "       'tele_full_b__address', 'fax_country_b__address', 'fax_area_b__address',\n",
      "       'fax_b__address', 'fax_full_b__address', 'hq_b__address'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from typing import Dict, Union, List\n",
    "import logging\n",
    "from functools import reduce\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from pandas.core.tools.datetimes import _guess_datetime_format_for_array\n",
    "\n",
    "# set logger level\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def data_into_dict(\n",
    "        filepath: Union[str, List], \n",
    ") -> Dict[str, pd.DataFrame]:   \n",
    "    \"\"\"Read data from paths into dictionary values\n",
    "    This is an example of Google style.\n",
    "\n",
    "    Args:\n",
    "        filepath (Union[str, List]) : string literal of list of strings pointing to files for io\n",
    "    Returns:\n",
    "        file_d: dictionary of files as dataframes, with key as filename abbreviation\n",
    "    \"\"\"\n",
    "    logging.info(f\"Filepaths: {filepath}\")\n",
    "    # create file dictionary\n",
    "    file_d = dict()\n",
    "    for f in filepath:\n",
    "        # get abbreviation for key\n",
    "        fname_abbr =  os.path.split(f)[1].split(\".\")[0]\n",
    "        logging.info(f\"Reading {f} into key {fname_abbr}\")\n",
    "        # read dataframe into value\n",
    "        file_d[fname_abbr] = pd.read_csv(f)\n",
    "    return file_d\n",
    "\n",
    "\n",
    "# read in data from dir\n",
    "data_path = \"../data/data/\"\n",
    "# group filenames by prefix\n",
    "a_files = data_into_dict(glob.glob(os.path.join(data_path, \"a__*\")))\n",
    "b_files = data_into_dict(glob.glob(os.path.join(data_path, \"b__*\")))\n",
    "\n",
    "# consolidate dataframe groups into merged structure \n",
    "def merge_all_frames(\n",
    "    frames: Dict, \n",
    "    on: str, \n",
    "    how: str, \n",
    "    rename_exclusions: List=[]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Merge all frames in list into single dataframe \n",
    "\n",
    "    Args:\n",
    "        frames (Dict) : dict of dfs with frame values to merge into single frame\n",
    "        on (str) : column to merge on \n",
    "        how (str) : merge type\n",
    "        rename (List) : list of columns to not rename\n",
    "    Returns:\n",
    "        frame_merged (pd.DataFrame): merged dataframe\n",
    "    \"\"\"\n",
    "    frames = deepcopy(frames)\n",
    "    # append df key names to columns to resolve conflicts in col names\n",
    "    for frame in frames.items(): \n",
    "        frames[frame[0]] = frame[1].rename({col:f\"{col}_{frame[0]}\" \\\n",
    "            for col in frame[1] if (col!=on) and (col not in rename_exclusions)}, axis=1)\n",
    "\n",
    "    # merge frames and set key value as conflicting column suffixes\n",
    "    logging.info(f\"Merging values of {frames.keys()}\")\n",
    "    frame_merged = reduce(\n",
    "                lambda  left,right: pd.merge(left,right,on=[on],how=how), frames.values()\n",
    "            )\n",
    "        \n",
    "    logging.info(f\"Merged frames into one with columns {frame_merged.columns}\")\n",
    "    return frame_merged\n",
    "\n",
    "a_frame = merge_all_frames(a_files, on=\"geo_id\", how='outer', rename_exclusions=['vendor_id'])\n",
    "b_frame = merge_all_frames(b_files, on=\"b_entity_id\", how='outer')\n",
    "\n",
    "a_frame = a_frame.set_index(\"vendor_id\").reset_index()\n",
    "b_frame = b_frame.set_index(\"b_entity_id\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:working on column vendor_id\n",
      "INFO:root:Numeric proportion for vendor_id: 0\n",
      "INFO:root:Converted column vendor_id into string type.\n",
      "INFO:root:working on column geo_id\n",
      "INFO:root:Numeric proportion for geo_id: 0\n",
      "INFO:root:Converted column geo_id into string type.\n",
      "INFO:root:working on column zipcode_a__geo\n",
      "INFO:root:Numeric proportion for zipcode_a__geo: 0\n",
      "INFO:root:Converted column zipcode_a__geo into string type.\n",
      "INFO:root:working on column is_primary_a__geo\n",
      "INFO:root:Numeric proportion for is_primary_a__geo: 0\n",
      "INFO:root:Converted column is_primary_a__geo into string type.\n",
      "INFO:root:working on column latitude_a__geo\n",
      "INFO:root:Numeric proportion for latitude_a__geo: 0.9874989934777357\n",
      "INFO:root:Converted column latitude_a__geo into float type.\n",
      "INFO:root:working on column longitude_a__geo\n",
      "INFO:root:Numeric proportion for longitude_a__geo: 0.9874989934777357\n",
      "INFO:root:Converted column longitude_a__geo into float type.\n",
      "INFO:root:working on column elevation_a__geo\n",
      "INFO:root:Numeric proportion for elevation_a__geo: 1.0\n",
      "INFO:root:Converted column elevation_a__geo into Int64 type.\n",
      "INFO:root:working on column state_a__geo\n",
      "INFO:root:Numeric proportion for state_a__geo: 0\n",
      "INFO:root:Converted column state_a__geo into string type.\n",
      "INFO:root:working on column state_full_name_a__geo\n",
      "INFO:root:Numeric proportion for state_full_name_a__geo: 0\n",
      "INFO:root:Converted column state_full_name_a__geo into string type.\n",
      "INFO:root:working on column area_code_a__geo\n",
      "INFO:root:Numeric proportion for area_code_a__geo: 0\n",
      "INFO:root:Converted column area_code_a__geo into string type.\n",
      "INFO:root:working on column city_a__geo\n",
      "INFO:root:Numeric proportion for city_a__geo: 0\n",
      "INFO:root:Converted column city_a__geo into string type.\n",
      "INFO:root:working on column city_display_a__geo\n",
      "INFO:root:Numeric proportion for city_display_a__geo: 0\n",
      "INFO:root:Converted column city_display_a__geo into string type.\n",
      "INFO:root:working on column county_a__geo\n",
      "INFO:root:Numeric proportion for county_a__geo: 0\n",
      "INFO:root:Converted column county_a__geo into string type.\n",
      "INFO:root:working on column county_fips_a__geo\n",
      "INFO:root:Numeric proportion for county_fips_a__geo: 0\n",
      "INFO:root:Converted column county_fips_a__geo into string type.\n",
      "INFO:root:working on column state_fips_a__geo\n",
      "INFO:root:Numeric proportion for state_fips_a__geo: 0\n",
      "INFO:root:Converted column state_fips_a__geo into string type.\n",
      "INFO:root:working on column timezone_a__geo\n",
      "INFO:root:Numeric proportion for timezone_a__geo: 1.0\n",
      "INFO:root:Converted column timezone_a__geo into Int64 type.\n",
      "INFO:root:working on column daylight_saving_a__geo\n",
      "INFO:root:Numeric proportion for daylight_saving_a__geo: 0\n",
      "INFO:root:Converted column daylight_saving_a__geo into string type.\n",
      "INFO:root:working on column region_a__geo\n",
      "INFO:root:Numeric proportion for region_a__geo: 0\n",
      "INFO:root:Converted column region_a__geo into string type.\n",
      "INFO:root:working on column division_a__geo\n",
      "INFO:root:Numeric proportion for division_a__geo: 0\n",
      "INFO:root:Converted column division_a__geo into string type.\n",
      "INFO:root:working on column congress_district_a__geo\n",
      "INFO:root:Numeric proportion for congress_district_a__geo: 0\n",
      "INFO:root:Converted column congress_district_a__geo into string type.\n",
      "INFO:root:working on column congress_land_area_a__geo\n",
      "INFO:root:Numeric proportion for congress_land_area_a__geo: 0.6346071275225419\n",
      "INFO:root:Converted column congress_land_area_a__geo into float type.\n",
      "INFO:root:working on column country_a__geo\n",
      "INFO:root:Numeric proportion for country_a__geo: 0\n",
      "INFO:root:Converted column country_a__geo into string type.\n",
      "INFO:root:working on column continent_a__geo\n",
      "INFO:root:Numeric proportion for continent_a__geo: 0\n",
      "INFO:root:Converted column continent_a__geo into string type.\n",
      "INFO:root:working on column country_iso2_a__geo\n",
      "INFO:root:Numeric proportion for country_iso2_a__geo: 0\n",
      "INFO:root:Converted column country_iso2_a__geo into string type.\n",
      "INFO:root:working on column parent_vendor_id_a__company\n",
      "INFO:root:Numeric proportion for parent_vendor_id_a__company: 1.0\n",
      "INFO:root:Converted column parent_vendor_id_a__company into Int64 type.\n",
      "INFO:root:working on column top_vendor_id_a__company\n",
      "INFO:root:Numeric proportion for top_vendor_id_a__company: 1.0\n",
      "INFO:root:Converted column top_vendor_id_a__company into Int64 type.\n",
      "INFO:root:working on column cnt_children_a__company\n",
      "INFO:root:Numeric proportion for cnt_children_a__company: 0\n",
      "INFO:root:Converted column cnt_children_a__company into string type.\n",
      "INFO:root:working on column orgtype_id_a__company\n",
      "INFO:root:Numeric proportion for orgtype_id_a__company: 0\n",
      "INFO:root:Converted column orgtype_id_a__company into string type.\n",
      "INFO:root:working on column name_a__company\n",
      "INFO:root:Numeric proportion for name_a__company: 0\n",
      "INFO:root:Converted column name_a__company into string type.\n",
      "INFO:root:working on column email_a__company\n",
      "INFO:root:Numeric proportion for email_a__company: 0\n",
      "INFO:root:Converted column email_a__company into string type.\n",
      "INFO:root:working on column phone_a__company\n",
      "INFO:root:Numeric proportion for phone_a__company: 0.00015026296018031557\n",
      "INFO:root:Converted column phone_a__company into string type.\n",
      "INFO:root:working on column fax_a__company\n",
      "INFO:root:Numeric proportion for fax_a__company: 0\n",
      "INFO:root:Converted column fax_a__company into string type.\n",
      "INFO:root:working on column dunsnumber_a__company\n",
      "INFO:root:Numeric proportion for dunsnumber_a__company: 0.9999638793570526\n",
      "INFO:root:Converted column dunsnumber_a__company into Int64 type.\n",
      "INFO:root:working on column websiteurl_a__company\n",
      "INFO:root:Numeric proportion for websiteurl_a__company: 0\n",
      "INFO:root:Converted column websiteurl_a__company into string type.\n",
      "INFO:root:working on column address_a__company\n",
      "INFO:root:Numeric proportion for address_a__company: 0\n",
      "INFO:root:Converted column address_a__company into string type.\n",
      "INFO:root:working on column address1_a__company\n",
      "INFO:root:Numeric proportion for address1_a__company: 0\n",
      "INFO:root:Converted column address1_a__company into string type.\n",
      "INFO:root:working on column address2_a__company\n",
      "INFO:root:Numeric proportion for address2_a__company: 0\n",
      "INFO:root:Converted column address2_a__company into string type.\n",
      "INFO:root:working on column country_a__company\n",
      "INFO:root:Numeric proportion for country_a__company: 0\n",
      "INFO:root:Converted column country_a__company into string type.\n",
      "INFO:root:working on column zipcode_a__company\n",
      "INFO:root:Numeric proportion for zipcode_a__company: 0\n",
      "INFO:root:Converted column zipcode_a__company into string type.\n",
      "INFO:root:working on column parentdunsnumber_a__company\n",
      "INFO:root:Numeric proportion for parentdunsnumber_a__company: 1.0\n",
      "INFO:root:Converted column parentdunsnumber_a__company into Int64 type.\n",
      "INFO:root:working on column score_a__company\n",
      "INFO:root:Numeric proportion for score_a__company: 0\n",
      "INFO:root:Converted column score_a__company into string type.\n",
      "INFO:root:working on column cnt_opp_a__company\n",
      "INFO:root:Numeric proportion for cnt_opp_a__company: 0\n",
      "INFO:root:Converted column cnt_opp_a__company into string type.\n",
      "INFO:root:working on column bucket_id_a__company\n",
      "INFO:root:Numeric proportion for bucket_id_a__company: 0\n",
      "INFO:root:Converted column bucket_id_a__company into string type.\n",
      "INFO:root:working on column load_date_a__company\n",
      "INFO:root:Numeric proportion for load_date_a__company: 0\n",
      "INFO:root:Converted column load_date_a__company into string type.\n",
      "INFO:root:working on column lvl_a__company\n",
      "INFO:root:Numeric proportion for lvl_a__company: 1.0\n",
      "INFO:root:Converted column lvl_a__company into Int64 type.\n"
     ]
    }
   ],
   "source": [
    "def type_compression(\n",
    "    frame: pd.DataFrame, \n",
    "    numeric_proportion_threshold: float=0.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compress types of values into a standard\n",
    "\n",
    "    Args:\n",
    "        frame (pd.DataFrame) : data frame to compress types\n",
    "        numeric_proportion_threshold (float) : proportion of values in mixed type column\n",
    "            that must pass numeric validation in order to convert that column to either float or int type\n",
    "    Returns: \n",
    "        frame_comp (pd.DataFrame) : compressed type data\n",
    "    \"\"\"\n",
    "    # get column types\n",
    "    col_types = frame.dtypes.to_dict()\n",
    "    # replace na value with string literal\n",
    "    frame = frame.fillna(\"null\")\n",
    "    # set heuristic inline function for testing non-null string values\n",
    "    non_null = lambda x: ('null' not in x.lower().replace(\" \", \"\")) \\\n",
    "        and ('nan' not in x.lower().replace(\" \", \"\"))\\\n",
    "        and ('notdefined' not in x.lower().replace(\" \", \"\"))\\\n",
    "        and ('na' not in x.lower().replace(\" \", \"\"))\n",
    "    # convert object types to string values\n",
    "    for col, datatype in col_types.items():\n",
    "        logging.info(f\"working on column {col}\")\n",
    "        frame[col] = frame[col].astype(str)\n",
    "        # get all values in series that are not null\n",
    "        non_null_index = frame[col].apply(non_null)\n",
    "        non_null_s = frame[col][non_null_index]\n",
    "        # create inline function for testing if data is numeric, only stripping dashes from left \n",
    "        isnum = lambda x: (x.lstrip(\"-\").replace(\".\", \"\").isnumeric()) and (x.count(\".\")==1)\n",
    "        isnum_s = non_null_s.apply(isnum)\n",
    "        isnum_sum, isnum_true = isnum_s.value_counts().sum(), isnum_s.value_counts().get(True)\n",
    "        # get proportion of numeric strings in non-null series\n",
    "        # get proportion is numeric values are present\n",
    "        if isnum_true:\n",
    "            isnum_prop = float(isnum_true)/float(isnum_sum)\n",
    "        else: \n",
    "            isnum_prop = 0\n",
    "        logging.info(f\"Numeric proportion for {col}: {isnum_prop}\")\n",
    "        # strip whitespace\n",
    "        frame[col] = frame[col].str.strip()\n",
    "        # check proprtion and convert based upon value\n",
    "        if isnum_prop >= numeric_proportion_threshold:\n",
    "            col_numeric = frame[col].apply(isnum)\n",
    "            # check for int values among all numeric values\n",
    "            int_check = frame[col][col_numeric]\\\n",
    "                .apply(lambda x: set(x.split(\".\")[-1]).issubset(\"0\") or x.isdigit())\n",
    "            if int_check.all():\n",
    "                # set null type\n",
    "                frame.loc[~col_numeric,col] = np.nan\n",
    "                # set type as int, with float conversion first\n",
    "                # to offset np.nan type data\n",
    "                frame[col] = frame[col].astype(\"float\")\n",
    "                frame[col] = frame[col].astype(\"Int64\")\n",
    "                logging.info(f\"Converted column {col} into Int64 type.\")\n",
    "            else: \n",
    "                # set null type\n",
    "                frame.loc[~col_numeric,col] = np.nan\n",
    "                # set type as float if non-int numeric values exist\n",
    "                frame[col] = frame[col].astype(\"float\")\n",
    "                logging.info(f\"Converted column {col} into float type.\")\n",
    "        # if non null values are not primarily numeric, then convert to lowercase\n",
    "        # and remove non-alphanumeric chars\n",
    "        else:\n",
    "            # convert all to lowercase\n",
    "            frame[col] = frame[col].apply(str.lower)\n",
    "            # create regex pattern for keeping only alphanumeric characters\n",
    "            frame.loc[non_null_index, col] = frame[col][non_null_index]\\\n",
    "                .apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', \"\", x))\n",
    "            # create regex pattern for removing redundant whitespace\n",
    "            frame.loc[non_null_index, col] = frame[col][non_null_index]\\\n",
    "                .apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "            # convert all null values to nan\n",
    "            frame.loc[~non_null_index,col] = np.nan\n",
    "            logging.info(f\"Converted column {col} into string type.\")\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "comp = type_compression(frame=a_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = a_frame\n",
    "col = \"address1_a__company\"\n",
    "frame = frame.fillna(\"null\")\n",
    "non_null = lambda x: bool('null' not in x.lower().replace(\" \", \"\"))\\\n",
    "        and ('nan' not in x.lower().replace(\" \", \"\"))\\\n",
    "        and ('notdefined' not in x.lower().replace(\" \", \"\"))\\\n",
    "        and ('na' not in x.lower().replace(\" \", \"\"))\n",
    "frame[col] = frame[col].astype(str)\n",
    "frame[col] = frame[col].str.strip()\n",
    "# convert all to lowercase\n",
    "frame[col] = frame[col].apply(str.lower)\n",
    "# create regex pattern for only alphanumeric characters\n",
    "\n",
    "\n",
    "# cut all non-alphanumeric characters from strings\n",
    "\n",
    "non_null_index = frame[col].apply(non_null)\n",
    "non_null_s = frame[col][non_null_index]\n",
    "frame.loc[non_null_index, col] = frame[col][non_null_index].apply(lambda x: re.sub(r'[^A-Za-z0-9 ]+', '', x))\n",
    "frame.loc[non_null_index, col] = frame[col][non_null_index].apply(lambda x: re.sub(' +', ' ', x))\n",
    "frame.loc[~non_null_index,col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>geo_id</th>\n",
       "      <th>zipcode_a__geo</th>\n",
       "      <th>is_primary_a__geo</th>\n",
       "      <th>latitude_a__geo</th>\n",
       "      <th>longitude_a__geo</th>\n",
       "      <th>elevation_a__geo</th>\n",
       "      <th>state_a__geo</th>\n",
       "      <th>state_full_name_a__geo</th>\n",
       "      <th>area_code_a__geo</th>\n",
       "      <th>...</th>\n",
       "      <th>address1_a__company</th>\n",
       "      <th>address2_a__company</th>\n",
       "      <th>country_a__company</th>\n",
       "      <th>zipcode_a__company</th>\n",
       "      <th>parentdunsnumber_a__company</th>\n",
       "      <th>score_a__company</th>\n",
       "      <th>cnt_opp_a__company</th>\n",
       "      <th>bucket_id_a__company</th>\n",
       "      <th>load_date_a__company</th>\n",
       "      <th>lvl_a__company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285924451</td>\n",
       "      <td>8278</td>\n",
       "      <td>14467</td>\n",
       "      <td>t</td>\n",
       "      <td>43.043294</td>\n",
       "      <td>-77.614181</td>\n",
       "      <td>513</td>\n",
       "      <td>ny</td>\n",
       "      <td>new york</td>\n",
       "      <td>585</td>\n",
       "      <td>...</td>\n",
       "      <td>205 summit point dr 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>14467</td>\n",
       "      <td>774581862</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47653720</td>\n",
       "      <td>3430</td>\n",
       "      <td>6258</td>\n",
       "      <td>t</td>\n",
       "      <td>41.897500</td>\n",
       "      <td>-71.963100</td>\n",
       "      <td>287</td>\n",
       "      <td>ct</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>860</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>06258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149196787</td>\n",
       "      <td>3430</td>\n",
       "      <td>6258</td>\n",
       "      <td>t</td>\n",
       "      <td>41.897500</td>\n",
       "      <td>-71.963100</td>\n",
       "      <td>287</td>\n",
       "      <td>ct</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>860</td>\n",
       "      <td>...</td>\n",
       "      <td>junction rte 101 and rte 169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>06258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>20180526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>274892372</td>\n",
       "      <td>3430</td>\n",
       "      <td>6258</td>\n",
       "      <td>t</td>\n",
       "      <td>41.897500</td>\n",
       "      <td>-71.963100</td>\n",
       "      <td>287</td>\n",
       "      <td>ct</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>860</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>06258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20180526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197539987</td>\n",
       "      <td>3430</td>\n",
       "      <td>6258</td>\n",
       "      <td>t</td>\n",
       "      <td>41.897500</td>\n",
       "      <td>-71.963100</td>\n",
       "      <td>287</td>\n",
       "      <td>ct</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>860</td>\n",
       "      <td>...</td>\n",
       "      <td>rt 101 po box 98 pomfret</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>06258</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76339</th>\n",
       "      <td>49244286</td>\n",
       "      <td>17923</td>\n",
       "      <td>29334</td>\n",
       "      <td>t</td>\n",
       "      <td>34.908130</td>\n",
       "      <td>-82.117325</td>\n",
       "      <td>816</td>\n",
       "      <td>sc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>2153</td>\n",
       "      <td>e main st 14</td>\n",
       "      <td>us</td>\n",
       "      <td>29334</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76340</th>\n",
       "      <td>21988338</td>\n",
       "      <td>4090</td>\n",
       "      <td>7430</td>\n",
       "      <td>t</td>\n",
       "      <td>41.077976</td>\n",
       "      <td>-74.176374</td>\n",
       "      <td>22</td>\n",
       "      <td>nj</td>\n",
       "      <td>new jersey</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>520 green mountain rd mahwah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>07430</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76341</th>\n",
       "      <td>36866816</td>\n",
       "      <td>4090</td>\n",
       "      <td>7430</td>\n",
       "      <td>t</td>\n",
       "      <td>41.077976</td>\n",
       "      <td>-74.176374</td>\n",
       "      <td>22</td>\n",
       "      <td>nj</td>\n",
       "      <td>new jersey</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>10 industrial ave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>07430</td>\n",
       "      <td>72704224</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76342</th>\n",
       "      <td>63214740</td>\n",
       "      <td>4090</td>\n",
       "      <td>7430</td>\n",
       "      <td>t</td>\n",
       "      <td>41.077976</td>\n",
       "      <td>-74.176374</td>\n",
       "      <td>22</td>\n",
       "      <td>nj</td>\n",
       "      <td>new jersey</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>115 franklin tpke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us</td>\n",
       "      <td>07430</td>\n",
       "      <td>884074209</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76343</th>\n",
       "      <td>146453881</td>\n",
       "      <td>338535</td>\n",
       "      <td>r3c3r1</td>\n",
       "      <td>t</td>\n",
       "      <td>49.937250</td>\n",
       "      <td>-97.116884</td>\n",
       "      <td>228</td>\n",
       "      <td>manitoba</td>\n",
       "      <td>manitoba</td>\n",
       "      <td>camb</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ca</td>\n",
       "      <td>r3c3r1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>20180526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76344 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vendor_id  geo_id zipcode_a__geo is_primary_a__geo  latitude_a__geo  \\\n",
       "0      285924451    8278          14467                 t        43.043294   \n",
       "1       47653720    3430           6258                 t        41.897500   \n",
       "2      149196787    3430           6258                 t        41.897500   \n",
       "3      274892372    3430           6258                 t        41.897500   \n",
       "4      197539987    3430           6258                 t        41.897500   \n",
       "...          ...     ...            ...               ...              ...   \n",
       "76339   49244286   17923          29334                 t        34.908130   \n",
       "76340   21988338    4090           7430                 t        41.077976   \n",
       "76341   36866816    4090           7430                 t        41.077976   \n",
       "76342   63214740    4090           7430                 t        41.077976   \n",
       "76343  146453881  338535         r3c3r1                 t        49.937250   \n",
       "\n",
       "       longitude_a__geo  elevation_a__geo state_a__geo state_full_name_a__geo  \\\n",
       "0            -77.614181               513           ny               new york   \n",
       "1            -71.963100               287           ct            connecticut   \n",
       "2            -71.963100               287           ct            connecticut   \n",
       "3            -71.963100               287           ct            connecticut   \n",
       "4            -71.963100               287           ct            connecticut   \n",
       "...                 ...               ...          ...                    ...   \n",
       "76339        -82.117325               816           sc                    NaN   \n",
       "76340        -74.176374                22           nj             new jersey   \n",
       "76341        -74.176374                22           nj             new jersey   \n",
       "76342        -74.176374                22           nj             new jersey   \n",
       "76343        -97.116884               228     manitoba               manitoba   \n",
       "\n",
       "      area_code_a__geo  ...           address1_a__company address2_a__company  \\\n",
       "0                  585  ...         205 summit point dr 2                 NaN   \n",
       "1                  860  ...                           NaN                 NaN   \n",
       "2                  860  ...  junction rte 101 and rte 169                 NaN   \n",
       "3                  860  ...                           NaN                 NaN   \n",
       "4                  860  ...      rt 101 po box 98 pomfret                 NaN   \n",
       "...                ...  ...                           ...                 ...   \n",
       "76339              864  ...                          2153        e main st 14   \n",
       "76340              201  ...  520 green mountain rd mahwah                 NaN   \n",
       "76341              201  ...             10 industrial ave                 NaN   \n",
       "76342              201  ...             115 franklin tpke                 NaN   \n",
       "76343             camb  ...                           NaN                 NaN   \n",
       "\n",
       "      country_a__company zipcode_a__company parentdunsnumber_a__company  \\\n",
       "0                     us              14467                   774581862   \n",
       "1                     us              06258                        <NA>   \n",
       "2                     us              06258                        <NA>   \n",
       "3                     us              06258                        <NA>   \n",
       "4                     us              06258                        <NA>   \n",
       "...                  ...                ...                         ...   \n",
       "76339                 us              29334                        <NA>   \n",
       "76340                 us              07430                        <NA>   \n",
       "76341                 us              07430                    72704224   \n",
       "76342                 us              07430                   884074209   \n",
       "76343                 ca             r3c3r1                        <NA>   \n",
       "\n",
       "       score_a__company cnt_opp_a__company bucket_id_a__company  \\\n",
       "0                    71                  0                   87   \n",
       "1                     0                  0                   99   \n",
       "2                     0                  0                   27   \n",
       "3                     0                  0                   20   \n",
       "4                     0                  0                   48   \n",
       "...                 ...                ...                  ...   \n",
       "76339                61                  0                    3   \n",
       "76340                 0                  0                   89   \n",
       "76341                46                  0                   90   \n",
       "76342                25                  0                   58   \n",
       "76343                56                  0                   12   \n",
       "\n",
       "      load_date_a__company lvl_a__company  \n",
       "0                 20180526              0  \n",
       "1                 20180526              0  \n",
       "2                 20180526              1  \n",
       "3                 20180526              1  \n",
       "4                 20180526              0  \n",
       "...                    ...            ...  \n",
       "76339             20180526              0  \n",
       "76340             20180526              0  \n",
       "76341             20180526              0  \n",
       "76342             20180526              0  \n",
       "76343             20180526              0  \n",
       "\n",
       "[76344 rows x 45 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2018-05-26\n",
       "1        2018-05-26\n",
       "2        2018-05-26\n",
       "3        2018-05-26\n",
       "4        2018-05-26\n",
       "            ...    \n",
       "76339    2018-05-26\n",
       "76340    2018-05-26\n",
       "76341    2018-05-26\n",
       "76342    2018-05-26\n",
       "76343    2018-05-26\n",
       "Name: load_date_a__company, Length: 76344, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_frame.load_date_a__company.to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('webscraping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e85b6ddbb5dc1028087489c79e17921036533c9bfed4bb1ebacd9fa0618340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
